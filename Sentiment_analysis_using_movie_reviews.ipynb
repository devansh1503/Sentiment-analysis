{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis using movie reviews.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXfx+LVbq6ANib9+urH1Gt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devansh1503/Sentiment-analysis/blob/main/Sentiment_analysis_using_movie_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SENTIMENT ANALYSIS USING MOVIE REVIEWS**"
      ],
      "metadata": {
        "id": "zlwmu4_74X_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part will import everything, and download the dataset from keras.\n",
        "in each review the words are already encoded, and encoded on basis of their frequency. Please do read the info available at keras official website."
      ],
      "metadata": {
        "id": "VhdZLONWAxHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ad9HXeY_hKM",
        "outputId": "3f5e4174-7988-460a-ab02-48a127f9d520"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accessing a data for example\n",
        "print(train_data[1])\n",
        "print(train_labels[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlMZbmo4BSMN",
        "outputId": "09762235-ed13-4b9e-b6e9-a620954fed59"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we would do some padding of the data to make each review of length 250, this is important for our neural network and thus it would add 0s or remove some elements from review accordingly."
      ],
      "metadata": {
        "id": "XMTbUMyWB8aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)"
      ],
      "metadata": {
        "id": "Y0m6c0cXCOY2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now creating the model,\n",
        "First layer: Word Embedding (Encoding the words in form of vectors to make them meaningful)\n",
        "Second layer: LSTM(Long short term memory, a method to perform task which would store the data from previous iterations)\n",
        "Third layer: Dense node with sigmoid function"
      ],
      "metadata": {
        "id": "ebNtuUvRCjmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCyXd3KLCiuZ",
        "outputId": "6790e1a8-fb9b-4f33-899b-a31487ebfcc8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 32)          2834688   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOVuXTD0EGGi",
        "outputId": "cf5d7068-8a68-4195-b2ca-ee944cee6b19"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 65s 101ms/step - loss: 0.4258 - acc: 0.8071 - val_loss: 0.2950 - val_acc: 0.8820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now evaluating the model"
      ],
      "metadata": {
        "id": "A_bGrbrTEuho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVaGYre_Ew-G",
        "outputId": "6be7e788-f5ec-4395-b97b-36c53b0a12bf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 18s 24ms/step - loss: 0.3042 - acc: 0.8740\n",
            "[0.3042070269584656, 0.873960018157959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAKING PREDICTIONS"
      ],
      "metadata": {
        "id": "-vHwKgL5HX-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly we need to make an encoding function which would encode our text to encoded version in the keras dataset."
      ],
      "metadata": {
        "id": "zkWccwzzHZux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index() #gets dict mapping of words in dataset\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text) \n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens] #encodes the data if the word is present in dataset, else puts 0\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0] #does padding upto 250 \n",
        "#example\n",
        "text = \"What a wonderful movie\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64OYX_yLHgjp",
        "outputId": "de626444-6d37-434b-f768-49e5f843eb5d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  48   3 386  17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could also make a decode function(Only for our simplicity, but is not needed)"
      ],
      "metadata": {
        "id": "_zbp7tXvIPBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "  \n",
        "print(decode_integers(train_data[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52tR_UfIYEe",
        "outputId": "52af963b-9610-45a2-ad10-2ff470307663"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the thought solid thought senator do making to is spot nomination assumed while he of jack in where picked as getting on was did hands fact characters to always life thrillers not as me can't in at are br of sure your way of little it strongly random to view of love it so principles of guy it used producer of where it of here icon film of outside to don't all unique some like of direction it if out her imagination below keep of queen he diverse to makes this stretch stefan of solid it thought begins br senator machinations budget worthwhile though ok brokedown awaiting for ever better were lugia diverse for budget look kicked any to of making it out bosworth's follows for effects show to show cast this family us scenes more it severe making senator to levant's finds tv tend to of emerged these thing wants but fuher an beckinsale cult as it is video do you david see scenery it in few those are of ship for with of wild to one is very work dark they don't do dvd with those them\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred) \n",
        "  if(result[0]>0.5):\n",
        "    print(\"Positive review\")\n",
        "  else:\n",
        "    print(\"Negative review\")\n",
        "  print(result[0])\n",
        "\n",
        "review = input(\"Enter your review: \")\n",
        "predict(review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SjBEDi5Jcn3",
        "outputId": "2611da78-e073-4e38-e60b-2ef003da3070"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your review: This movie was fantastic!\n",
            "Positive review\n",
            "[0.5902109]\n"
          ]
        }
      ]
    }
  ]
}